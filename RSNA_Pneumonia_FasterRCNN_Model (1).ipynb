{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50db4ece",
   "metadata": {},
   "source": [
    "Madi from Image Reserach center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fff5f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-31T12:35:42.324903Z",
     "start_time": "2022-03-31T12:35:42.321392Z"
    }
   },
   "outputs": [],
   "source": [
    "# ###LDA Object Detection RSNA Database\n",
    "\n",
    "# #!conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch\n",
    "\n",
    "\n",
    "# #Please install all libraries\n",
    "# !pip install opencv-python\n",
    "# !pip install unet\n",
    "# !pip install scipy\n",
    "# !pip install seaborn\n",
    "# !pip install h5py\n",
    "# !pip install utils\n",
    "# !pip install pandas\n",
    "# !pip install matplotlib\n",
    "# !pip install nibabel\n",
    "# !pip install SimpleITK\n",
    "# !pip install scikit-plot\n",
    "# !pip install tqdm\n",
    "# !pip install scikit-image\n",
    "# !pip install ipywidgets\n",
    "# !pip install torchvision\n",
    "# !pip install torchio\n",
    "# !pip install albumentations\n",
    "# !pip install -q pydicom \n",
    "# !pip install -q imgaug\n",
    "# !pip install -U albumentations\n",
    "# !pip install minio\n",
    "# !pip install python-dotenv\n",
    "# !pip install boto3\n",
    "# !pip install plotly\n",
    "#!pip install mlxtend\n",
    "#!pip install detecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841075e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T18:00:55.472634Z",
     "start_time": "2022-04-04T18:00:51.605850Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import math\n",
    "import time\n",
    "import sys\n",
    "import cv2\n",
    "import os\n",
    "import scipy\n",
    "import enum\n",
    "import random\n",
    "import h5py\n",
    "import zipfile\n",
    "import itertools\n",
    "import json\n",
    "import seaborn as sns\n",
    "import pydicom as dcm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import scipy.ndimage.morphology as morphology\n",
    "import scipy.ndimage as ndimage\n",
    "import scipy.ndimage.filters as filters\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as im\n",
    "import matplotlib.image as img\n",
    "import nibabel as nib\n",
    "import SimpleITK as sitk\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pydicom \n",
    "from itertools import product\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "from scipy import stats\n",
    "from scipy import ndimage\n",
    "from pathlib import Path\n",
    "from pathlib import Path\n",
    "#from unet import UNet\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "from os.path import join, basename, isdir\n",
    "from scikitplot.metrics import plot_confusion_matrix, plot_roc\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm.notebook import trange, tqdm, tqdm_notebook\n",
    "from detecto import core, utils, visualize\n",
    "from detecto.visualize import show_labeled_image, plot_prediction_grid\n",
    "\n",
    "from pydicom import dcmread\n",
    "from glob import glob\n",
    "from skimage.measure import label\n",
    "from skimage.transform import resize\n",
    "from skimage import io, measure\n",
    "from nibabel.testing import data_path\n",
    "from ipywidgets import interact, fixed\n",
    "from IPython import display\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a359cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T18:00:57.009325Z",
     "start_time": "2022-04-04T18:00:55.475771Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchio as tio\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.utils\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "from torchvision import transforms\n",
    "from torchvision import transforms as T\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchio.transforms import HistogramStandardization\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import albumentations as A\n",
    "from albumentations import (\n",
    "    Resize,\n",
    "    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose\n",
    ")\n",
    "\n",
    "\n",
    "print('TorchIO version:', tio.__version__)\n",
    "print('Torch version:', tio.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf744ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T18:00:57.207299Z",
     "start_time": "2022-04-04T18:00:57.012837Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45c9e75",
   "metadata": {},
   "source": [
    "##  Setup Data Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a941691",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a268b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T18:01:56.981171Z",
     "start_time": "2022-04-04T18:01:55.359333Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4054c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T18:02:13.485090Z",
     "start_time": "2022-04-04T18:02:13.475221Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8684c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T18:02:19.121164Z",
     "start_time": "2022-04-04T18:02:19.111906Z"
    }
   },
   "outputs": [],
   "source": [
    "#os.chdir('/workspace/LDA_Object_Detection/')\n",
    "images_path = 'D:/Datasets/LDA/RSNA/stage_2_train_images/'\n",
    "print(os.getcwd())\n",
    "print(images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fc2a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir(images_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7713af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images_path[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f43342",
   "metadata": {},
   "source": [
    "## Excel Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0cb8cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T18:02:23.428081Z",
     "start_time": "2022-04-04T18:02:23.284745Z"
    }
   },
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(os.path.join('stage_2_train_labels.csv'))\n",
    "class_labels = pd.read_csv(os.path.join('stage_2_detailed_class_info.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c4d3f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T18:02:23.966328Z",
     "start_time": "2022-04-04T18:02:23.914650Z"
    }
   },
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8b10ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T18:02:24.451242Z",
     "start_time": "2022-04-04T18:02:24.426200Z"
    }
   },
   "outputs": [],
   "source": [
    "class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f73781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e723a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we can see that all the null column values are with Target 0 indicating that those patients do not have penumonia\n",
    "train_labels[train_labels.isnull().any(axis=1)].Target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72782221",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we can see that all the non null column values are with Target 1 indicating that those patients have pneumonia\n",
    "train_labels[~train_labels.isnull().any(axis=1)].Target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c5261b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_labels.drop_duplicates(\"patientId\")\n",
    "# train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce2c975",
   "metadata": {},
   "source": [
    "#### PatientId \n",
    "A patientId. Each patientId corresponds to a unique image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5950f1",
   "metadata": {},
   "source": [
    "#### Class \n",
    "Have three values depending what is the current state of the patient's lung: 'No Lung Opacity / Not Normal', 'Normal' and 'Lung Opacity'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f321a8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T18:02:25.976493Z",
     "start_time": "2022-04-04T18:02:25.955463Z"
    }
   },
   "outputs": [],
   "source": [
    "# print('First five rows of Training set:\\n', train_labels.head())\n",
    "# print(train_labels.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc969cb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T18:02:26.431304Z",
     "start_time": "2022-04-04T18:02:26.421534Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(train_labels.iloc[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22d1969",
   "metadata": {},
   "source": [
    "#### Some information about the data field present in the 'stage_2_train_labels.csv' are:\n",
    "\n",
    "-patientId - A patientId. Each patientId corresponds to a unique image (which we will see a little bit later)\n",
    "\n",
    "-x - The upper-left x coordinate of the bounding box\n",
    "\n",
    "-y - The upper-left y coordinate of the bounding box\n",
    "\n",
    "-width - The width of the bounding box\n",
    "\n",
    "-height - The height of the bounding box\n",
    "\n",
    "-Target - The binary Target indicating whether this sample has evidence of pneumonia or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10101b06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T18:02:27.686384Z",
     "start_time": "2022-04-04T18:02:27.651695Z"
    }
   },
   "outputs": [],
   "source": [
    "# Number of duplicates in patientId:\n",
    "print('Number of unique patientId are: {}'.format(train_labels['patientId'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955e0ba0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T18:02:28.390946Z",
     "start_time": "2022-04-04T18:02:28.268875Z"
    }
   },
   "outputs": [],
   "source": [
    "bounding_box = train_labels.groupby('patientId').size().to_frame('number_of_boxes').reset_index()\n",
    "train_labels = train_labels.merge(bounding_box, on = 'patientId', how = 'left')\n",
    "print('Number of patientIds per bounding box in the dataset: ')\n",
    "(bounding_box.groupby('number_of_boxes').size().to_frame('number_of_patientId').reset_index().set_index('number_of_boxes').sort_values(by = 'number_of_boxes'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323261a2",
   "metadata": {},
   "source": [
    "#### Classes Information/ Number of Target =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63b2fe7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T18:03:15.204118Z",
     "start_time": "2022-04-04T18:02:39.656169Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Original dataframe shape:', train_labels.shape)\n",
    "\n",
    "train_labels_pos = pd.DataFrame(columns=['patientId', 'x', 'y', 'width', 'height'])\n",
    "k = 0\n",
    "for i in range(len(train_labels)):\n",
    "    if train_labels.loc[i]['Target'] == 1:\n",
    "        train_labels_pos.loc[k] = train_labels.loc[i]\n",
    "        k += 1\n",
    "\n",
    "print('Positive instances dataframe shape:', train_labels_pos.shape)\n",
    "train_paths = [os.path.join(images_path, image[0]) for image in train_labels_pos.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfce3b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998fd0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37927979",
   "metadata": {},
   "source": [
    "# Visualization of the images and the areas of inflammation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebefbe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(num_to_show=9):\n",
    "    \n",
    "    plt.figure(figsize=(20,20))\n",
    "    \n",
    "    for i in range(num_to_show):\n",
    "        plt.subplot(3, 3, i+1)\n",
    "        plt.grid(False)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        \n",
    "        img_dcm = dcmread(f'{train_paths[i+20]}.dcm')\n",
    "        img_np = img_dcm.pixel_array\n",
    "        plt.imshow(img_np, cmap='bone')\n",
    "        print(img_np.shape)\n",
    "\n",
    "imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79477eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_with_bboxes(num_to_show=9):\n",
    "    plt.figure(figsize=(20,20))\n",
    "    \n",
    "    for i in range(num_to_show):\n",
    "        plt.subplot(3, 3, i+1)\n",
    "        plt.grid(False)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        \n",
    "        id_= np.random.choice(train_labels_pos['patientId'].values)\n",
    "\n",
    "        current_axis = plt.gca()\n",
    "        img=pydicom.read_file(os.path.join(images_path,id_+'.dcm')).pixel_array\n",
    "        plt.imshow(img,cmap='bone')\n",
    "        print(img.shape)\n",
    "\n",
    "\n",
    "        current_axis = plt.gca()\n",
    "        boxes=train_labels_pos[['x','y','width','height']][train_labels_pos['patientId']==id_].values\n",
    "        for box in boxes:\n",
    "            x=box[0]\n",
    "            y=box[1]\n",
    "            w=box[2]\n",
    "            h=box[3]\n",
    "            current_axis.add_patch(plt.Rectangle((x, y), w, h, color='red', fill=False, linewidth=3)) \n",
    "        \n",
    "show_image_with_bboxes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908ed672",
   "metadata": {},
   "source": [
    "# Visualization of one image with area of inflammation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e60dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_one_annot(data, patient_id):\n",
    "    boxes_array = data[data[\"patientId\"] == patient_id][[\"x\", \"y\", \"width\", \"height\"]].values\n",
    "    print(boxes_array.dtype)\n",
    "    return boxes_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cc83af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_one_with_bbox(id_):\n",
    "    plt.figure(figsize=(20,20))\n",
    "    current_axis = plt.gca()\n",
    "    img=pydicom.read_file(os.path.join(images_path,id_+'.dcm')).pixel_array\n",
    "    plt.imshow(img,cmap='bone')\n",
    "\n",
    "    current_axis = plt.gca()\n",
    "    boxes=train_labels_pos[['x','y','width','height']][train_labels_pos['patientId']==id_].values\n",
    "    for box in boxes:\n",
    "        x=box[0]\n",
    "        y=box[1]\n",
    "        w=box[2]\n",
    "        h=box[3]\n",
    "        current_axis.add_patch(plt.Rectangle((x, y), w, h, color='red', fill=False, linewidth=3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd564f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_= np.random.choice(train_labels_pos['patientId'].values)\n",
    "print('Id', id_)\n",
    "print('Bboxes', parse_one_annot(train_labels_pos, id_))\n",
    "show_one_with_bbox(id_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62aac26",
   "metadata": {},
   "source": [
    "# Preparing data for training. Dataset class. Tranformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce832742",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T18:03:15.219440Z",
     "start_time": "2022-04-04T18:03:15.207499Z"
    }
   },
   "outputs": [],
   "source": [
    "class PneumoniaDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_dir, transforms=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.image_ids = dataframe['patientId'].unique()\n",
    "        self.df = dataframe\n",
    "        self.image_dir = image_dir\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # load images and bounding boxes   \n",
    "        image_id = self.image_ids[index]\n",
    "        records = self.df[self.df['patientId'] == image_id]\n",
    "        \n",
    "        img_path = os.path.join(self.image_dir, image_id)\n",
    "        img=pydicom.read_file(os.path.join(img_path +'.dcm')).pixel_array\n",
    "        img=img.astype(np.double)\n",
    "        img /= 255.0  \n",
    "        \n",
    "        # BB cordinates\n",
    "        \n",
    "        records = records.astype({\"x\": float, \"y\": float, \"height\": float, \"width\": float})\n",
    "        boxes = records[['x', 'y', 'width', 'height']].values\n",
    "        \n",
    "    \n",
    "        boxes[:, 2] = boxes[:, 0] + boxes[:, 2]\n",
    "        boxes[:, 3] = boxes[:, 1] + boxes[:, 3]\n",
    "\n",
    "        # Count the area and convert to tensor\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0]) \n",
    "        area = torch.as_tensor(area, dtype=torch.float32)                                  \n",
    "        \n",
    "        # We have only one class\n",
    "        labels = torch.ones((records.shape[0],), dtype=torch.int64)\n",
    "        \n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.zeros((records.shape[0],), dtype=torch.int64)       \n",
    "\n",
    "        \n",
    "        \n",
    "        # Bonding Box is in dictionary format\n",
    "        target = {}    \n",
    "        target['boxes'] = boxes\n",
    "        target['labels'] = labels\n",
    "        target['patientId'] = torch.tensor([index])\n",
    "        target['area'] = area\n",
    "        target['iscrowd'] = iscrowd\n",
    "                      \n",
    "        if self.transforms:\n",
    "            sample = {\n",
    "                'image': img,\n",
    "                'bboxes': target['boxes'],\n",
    "                'labels': labels\n",
    "            }\n",
    "            sample = self.transforms(**sample)\n",
    "            img = sample['image']\n",
    "            target['boxes'] = torch.stack(tuple(map(torch.FloatTensor, zip(*sample['bboxes'])))).permute(1, 0)\n",
    "            #target['boxes'] = torch.stack(list((map(torch.tensor, target['boxes'])))).type(torch.float32)\n",
    "\n",
    "        return img, target\n",
    "    \n",
    "    # return the number of dataset\n",
    "    def __len__(self):   #-> int:\n",
    "        #return self.image_ids.shape[0]  \n",
    "        return len(self.image_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dcd729",
   "metadata": {},
   "source": [
    "# Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b58064f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T18:03:15.227448Z",
     "start_time": "2022-04-04T18:03:15.222383Z"
    }
   },
   "outputs": [],
   "source": [
    "# Albumentations\n",
    "#https://albumentations.ai/docs/examples/example_bboxes2/\n",
    "#conda install -c conda-forge albumentations\n",
    "\n",
    "\n",
    "def get_train_transform():\n",
    "    return A.Compose([\n",
    "        #Resize(300,  300),\n",
    "#         A.Flip(0.5),\n",
    "#         A.RandomRotate90(0.5),\n",
    "#         MotionBlur(p=0.2),\n",
    "#         MedianBlur(blur_limit=3, p=0.1),\n",
    "#         Blur(blur_limit=3, p=0.1),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
    "\n",
    "def get_valid_transform():\n",
    "    return A.Compose([\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a0e24c",
   "metadata": {},
   "source": [
    "# Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad6c7db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T18:03:15.245060Z",
     "start_time": "2022-04-04T18:03:15.229726Z"
    }
   },
   "outputs": [],
   "source": [
    "#input_folder = '../input/rsna-pneumonia-detection-2018/input'\n",
    "images_folder = r'D:\\Datasets\\LDA\\RSNA\\stage_2_train_images'\n",
    "\n",
    "image_ids = train_labels_pos['patientId'].unique()\n",
    "train_ids = image_ids[:-300]\n",
    "valid_ids = image_ids[-300:]\n",
    "\n",
    "print(f\"Training instance: {len(train_ids)}\")\n",
    "print(f\"Validation instances: {len(valid_ids)}\")\n",
    "\n",
    "valid_df = train_labels_pos[train_labels_pos['patientId'].isin(valid_ids)]\n",
    "train_df = train_labels_pos[train_labels_pos['patientId'].isin(train_ids)]\n",
    "\n",
    "print('Train dataframe shape:', train_df.shape)\n",
    "print('Valid dataframe shape:', valid_df.shape)\n",
    "    \n",
    "train_dataset = PneumoniaDataset(train_df, images_folder, get_train_transform())\n",
    "valid_dataset = PneumoniaDataset(valid_df, images_folder, get_valid_transform())\n",
    "print('train_dataset and valid_dataset are loaded :)')   \n",
    "print(\"We have: {} training examples and {} validation examples\".format(len(train_dataset), len(valid_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868fbcde",
   "metadata": {},
   "source": [
    "# Check the custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d240b1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PneumoniaDataset(train_df, images_folder, get_train_transform())\n",
    "\n",
    "train_dataset[1][0]\n",
    "#train_dataset.__getitem__(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36b4400",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PneumoniaDataset(train_df, images_folder, get_train_transform())\n",
    "image = iter(train_dataset)\n",
    "img, targets = next(image)\n",
    "print(f'Tensor:{img}, Label:{label}')\n",
    "img = np.transpose(img, (1, 2, 0))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae50af46",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(2,2, figsize=(9,9))\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        random_index = np.random.randint(0, 240)\n",
    "        x_ray, label = train_dataset[random_index]\n",
    "        axis[i][j].imshow(x_ray[0], cmap=\"bone\")\n",
    "        axis[i][j].set_title(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a41f8f",
   "metadata": {},
   "source": [
    "# Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34383b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T18:13:37.687296Z",
     "start_time": "2022-04-04T18:13:37.684014Z"
    }
   },
   "outputs": [],
   "source": [
    "# collate_fn needs for batch\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25497223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def collate_fn(batch):\n",
    "#     return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97de23f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T18:13:38.344535Z",
     "start_time": "2022-04-04T18:13:38.335519Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, collate_fn=collate_fn) #, num_workers=2, collate_fn=collate_fn)\n",
    "valid_data_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn) #, num_workers=2, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba467e0",
   "metadata": {},
   "source": [
    "# Check dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cb3e5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# batch = iter(train_data_loader)\n",
    "# images, targets = next(batch)\n",
    "# image_grid = torchvision.utils.make_grid(images[:4])\n",
    "# image_np = image_grid.numpy()\n",
    "# img = np.transpose(image_np, (1, 2, 0))\n",
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8b9432",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets = next(iter(train_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d743e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa40da94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###https://stackoverflow.com/questions/5558418/list-of-dicts-to-from-dict-of-lists\n",
    "\n",
    "# # DataLoader is iterable over Dataset\n",
    "# for images, targets in train_data_loader:\n",
    "#     images = list(image.to(device) for image in images)\n",
    "#     #print(targets)\n",
    "    \n",
    "#     targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "#     #targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "#     #targets = {k: v.to(device) for k, v in targets.items()}\n",
    "#     print(targets)\n",
    "        \n",
    "#     ##Convert DL = targets\n",
    "    \n",
    "# #     targets = [dict(zip(targets,t)) for t in zip(*targets.values())]\n",
    "    \n",
    "# #     print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b552eca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Checking\n",
    "\n",
    "# boxes = targets[1]['boxes'].cpu().numpy().astype(np.int64)\n",
    "# print(boxes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c31aa67",
   "metadata": {},
   "source": [
    "# Helper Funtions in Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cef22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_image_precision(gts, preds, thresholds = (0.5, ), form = 'coco') -> float:\n",
    "    # https://www.kaggle.com/sadmanaraf/wheat-detection-using-faster-rcnn-train\n",
    "    \"\"\"Calculates image precision.\n",
    "\n",
    "    Args:\n",
    "        gts: (List[List[Union[int, float]]]) Coordinates of the available ground-truth boxes\n",
    "        preds: (List[List[Union[int, float]]]) Coordinates of the predicted boxes,\n",
    "               sorted by confidence value (descending)\n",
    "        thresholds: (float) Different thresholds\n",
    "        form: (str) Format of the coordinates\n",
    "\n",
    "    Return:\n",
    "        (float) Precision\n",
    "    \"\"\"\n",
    "    n_threshold = len(thresholds)\n",
    "    image_precision = 0.0\n",
    "    \n",
    "    ious = np.ones((len(gts), len(preds))) * -1\n",
    "    # ious = None\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        precision_at_threshold = calculate_precision(gts.copy(), preds, threshold=threshold,\n",
    "                                                     form=form, ious=ious)\n",
    "        image_precision += precision_at_threshold / n_threshold\n",
    "\n",
    "    return image_precision\n",
    "\n",
    "\n",
    "def calculate_iou(gt, pr, form='pascal_voc') -> float:\n",
    "    # https://www.kaggle.com/sadmanaraf/wheat-detection-using-faster-rcnn-train\n",
    "    \"\"\"Calculates the Intersection over Union.\n",
    "\n",
    "    Args:\n",
    "        gt: (np.ndarray[Union[int, float]]) coordinates of the ground-truth box\n",
    "        pr: (np.ndarray[Union[int, float]]) coordinates of the prdected box\n",
    "        form: (str) gt/pred coordinates format\n",
    "            - pascal_voc: [xmin, ymin, xmax, ymax]\n",
    "            - coco: [xmin, ymin, w, h]\n",
    "    Returns:\n",
    "        (float) Intersection over union (0.0 <= iou <= 1.0)\n",
    "    \"\"\"\n",
    "    if form == 'coco':\n",
    "        gt = gt.copy()\n",
    "        pr = pr.copy()\n",
    "\n",
    "        gt[2] = gt[0] + gt[2]\n",
    "        gt[3] = gt[1] + gt[3]\n",
    "        pr[2] = pr[0] + pr[2]\n",
    "        pr[3] = pr[1] + pr[3]\n",
    "\n",
    "    # Calculate overlap area\n",
    "    dx = min(gt[2], pr[2]) - max(gt[0], pr[0]) + 1\n",
    "    \n",
    "    if dx < 0:\n",
    "        return 0.0\n",
    "    dy = min(gt[3], pr[3]) - max(gt[1], pr[1]) + 1\n",
    "\n",
    "    if dy < 0:\n",
    "        return 0.0\n",
    "\n",
    "    overlap_area = dx * dy\n",
    "\n",
    "    # Calculate union area\n",
    "    union_area = (\n",
    "            (gt[2] - gt[0] + 1) * (gt[3] - gt[1] + 1) +\n",
    "            (pr[2] - pr[0] + 1) * (pr[3] - pr[1] + 1) -\n",
    "            overlap_area\n",
    "    )\n",
    "\n",
    "    return overlap_area / union_area\n",
    "\n",
    "\n",
    "def find_best_match(gts, pred, pred_idx, threshold = 0.5, form = 'pascal_voc', ious=None) -> int:\n",
    "    # https://www.kaggle.com/sadmanaraf/wheat-detection-using-faster-rcnn-train\n",
    "    \"\"\"Returns the index of the 'best match' between the\n",
    "    ground-truth boxes and the prediction. The 'best match'\n",
    "    is the highest IoU. (0.0 IoUs are ignored).\n",
    "\n",
    "    Args:\n",
    "        gts: (List[List[Union[int, float]]]) Coordinates of the available ground-truth boxes\n",
    "        pred: (List[Union[int, float]]) Coordinates of the predicted box\n",
    "        pred_idx: (int) Index of the current predicted box\n",
    "        threshold: (float) Threshold\n",
    "        form: (str) Format of the coordinates\n",
    "        ious: (np.ndarray) len(gts) x len(preds) matrix for storing calculated ious.\n",
    "\n",
    "    Return:\n",
    "        (int) Index of the best match GT box (-1 if no match above threshold)\n",
    "    \"\"\"\n",
    "    best_match_iou = -np.inf\n",
    "    best_match_idx = -1\n",
    "    for gt_idx in range(len(gts)):\n",
    "        \n",
    "        if gts[gt_idx][0] < 0:\n",
    "            # Already matched GT-box\n",
    "            continue\n",
    "        \n",
    "        iou = -1 if ious is None else ious[gt_idx][pred_idx]\n",
    "\n",
    "        if iou < 0:\n",
    "            iou = calculate_iou(gts[gt_idx], pred, form=form)\n",
    "            \n",
    "            if ious is not None:\n",
    "                ious[gt_idx][pred_idx] = iou\n",
    "\n",
    "        if iou < threshold:\n",
    "            continue\n",
    "\n",
    "        if iou > best_match_iou:\n",
    "            best_match_iou = iou\n",
    "            best_match_idx = gt_idx\n",
    "\n",
    "    return best_match_idx\n",
    "\n",
    "def calculate_precision(gts, preds, threshold = 0.5, form = 'coco', ious=None) -> float:\n",
    "    # https://www.kaggle.com/sadmanaraf/wheat-detection-using-faster-rcnn-train\n",
    "    \"\"\"Calculates precision for GT - prediction pairs at one threshold.\n",
    "\n",
    "    Args:\n",
    "        gts: (List[List[Union[int, float]]]) Coordinates of the available ground-truth boxes\n",
    "        preds: (List[List[Union[int, float]]]) Coordinates of the predicted boxes,\n",
    "               sorted by confidence value (descending)\n",
    "        threshold: (float) Threshold\n",
    "        form: (str) Format of the coordinates\n",
    "        ious: (np.ndarray) len(gts) x len(preds) matrix for storing calculated ious.\n",
    "\n",
    "    Return:\n",
    "        (float) Precision\n",
    "    \"\"\"\n",
    "    n = len(preds)\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    \n",
    "    for pred_idx in range(n):\n",
    "\n",
    "        best_match_gt_idx = find_best_match(gts, preds[pred_idx], pred_idx,\n",
    "                                            threshold=threshold, form=form, ious=ious)\n",
    "\n",
    "        if best_match_gt_idx >= 0:\n",
    "            # True positive: The predicted box matches a gt box with an IoU above the threshold.\n",
    "            tp += 1\n",
    "            # Remove the matched GT box\n",
    "            gts[best_match_gt_idx] = -1\n",
    "        else:\n",
    "            # No match\n",
    "            # False positive: indicates a predicted box had no associated gt box.\n",
    "            fp += 1\n",
    "\n",
    "    # False negative: indicates a gt box had no associated predicted box.\n",
    "    fn = (gts.sum(axis=1) > 0).sum()\n",
    "\n",
    "    return tp / (tp + fp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426d7b24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T18:13:41.201528Z",
     "start_time": "2022-04-04T18:13:41.185620Z"
    }
   },
   "outputs": [],
   "source": [
    "class Averager:\n",
    "    def __init__(self):\n",
    "        self.current_total = 0.0\n",
    "        self.iterations = 0.0\n",
    "\n",
    "    def send(self, value):\n",
    "        self.current_total += value\n",
    "        self.iterations += 1\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        if self.iterations == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1.0 * self.current_total / self.iterations\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_total = 0.0\n",
    "        self.iterations = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6234d41a",
   "metadata": {},
   "source": [
    "# Train and Validate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad1d9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, lr_scheduler, model, optimizer, \n",
    "          device, epoch, loss_hist, itr):\n",
    "    model.train()\n",
    "    start = time.time()\n",
    "    loss_hist.reset()\n",
    "    for images, targets in dataloader:\n",
    "        \n",
    "        images = list(image.to(device, dtype=torch.float) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "    \n",
    "#         print('Targets has: ',  targets)\n",
    "#         print('images has: ',  images)\n",
    "        \n",
    "#         print('Targets has: ', targets[0].keys())\n",
    "#         print(\"my image  : \",images[0])\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "\n",
    "\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        loss_value = losses.item()\n",
    "\n",
    "        loss_hist.send(loss_value)\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if itr % 100 == 0:                                                     # if itr % 50 == 0:\n",
    "            print(f\"Epoch #{epoch} iteration #{itr} loss: {loss_value}\")\n",
    "\n",
    "        itr += 1\n",
    "    \n",
    "    end = time.time()\n",
    "    return loss_hist, end, start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d54361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(dataloader, model, device, iou_thresholds):\n",
    "    valid_image_precision = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():  # Gradient calculation will turn off in prediction phase\n",
    "        for images, targets in dataloader:\n",
    "\n",
    "            images = list(image.to(device, dtype=torch.float) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            outputs = model(images)\n",
    "            \n",
    "    for i, image in enumerate(images):\n",
    "        boxes = outputs[i]['boxes'].data.cpu().numpy()\n",
    "        scores = outputs[i]['scores'].data.cpu().numpy()\n",
    "        gt_boxes = targets[i]['boxes'].cpu().numpy()\n",
    "        preds_sorted_idx = np.argsort(scores)[::-1]\n",
    "        preds_sorted = boxes[preds_sorted_idx]\n",
    "        image_precision = calculate_image_precision(preds_sorted,\n",
    "                                                        gt_boxes,\n",
    "                                                        thresholds=iou_thresholds,\n",
    "                                                        form='coco')\n",
    "        \n",
    "        print(\"precision  : \",image_precision)\n",
    "        \n",
    "        valid_image_precision.append(image_precision)\n",
    "\n",
    "    valid_prec = np.mean(valid_image_precision)\n",
    "    return valid_prec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ceea89",
   "metadata": {},
   "source": [
    "# Load FasterRCNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee71458",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T18:13:43.771488Z",
     "start_time": "2022-04-04T18:13:43.763352Z"
    }
   },
   "outputs": [],
   "source": [
    "#https://pytorch.org/vision/stable/generated/torchvision.models.detection.fasterrcnn_resnet50_fpn.html\n",
    "\n",
    "#model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "def get_model():\n",
    "    # load an object detection model pre-trained on COCO\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True, min_size=1024)\n",
    "    \n",
    "    # one class is pneumonia, and the other is background\n",
    "    num_classes = 2\n",
    "    # get the number of input features for the classifier (transfer features fron RPN to ROI pooling)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new on\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40ec2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74db382",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8139a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://github.com/ajinkya98/TensorBoard_PyTorch/blob/master/model.py\n",
    "# from itertools import product\n",
    "# # Hyperparameters\n",
    "# parameters = dict(\n",
    "#     lr = [0.0001, 0.00001],\n",
    "#     batch_size = [256, 512],\n",
    "#     #shuffle = [True, False]\n",
    "# )\n",
    "# param_values = [v for v in parameters.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d949414e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T18:13:50.486397Z",
     "start_time": "2022-04-04T18:13:44.535019Z"
    }
   },
   "outputs": [],
   "source": [
    "### https://pytorch.org/docs/stable/optim.html\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# learning parameters\n",
    "num_epochs = 25\n",
    "lr = 0.000885\n",
    "batch_size = 4\n",
    "\n",
    "model = get_model().to(device)\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "optimizer = torch.optim.SGD(params, lr=lr, momentum=0.1, weight_decay=0.0005)\n",
    "#optimizer = torch.optim.Adam(params, lr=1e-2, betas=(0.9,0.999), eps=1e-08,  weight_decay=0.0)\n",
    "#optimizer = torch.optim.RMSprop(params, lr=lr,alpha=0.99, weight_decay=0.9,momentum=0.1,centered=False)\n",
    "# optimizer = torch.optim.SparseAdam(params, lr=lr, betas=(0.9, 0.999), eps=1e-08)\n",
    "# optimizer = torch.optim.Adamax(params, lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "# optimizer = torch.optim.AdamW(params, lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False, *, maximize=False)\n",
    "# optimizer = torch.optim.Adagrad(params, lr=lr, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10)\n",
    "# optimizer = torch.optim.Adadelta(params, lr=lr, rho=0.9, eps=1e-06, weight_decay=0)\n",
    "#optimizer = torch.optim.ASGD(params, lr=lr, lambd=0.0001, alpha=0.9, t0=1000000.0, weight_decay=0.005)\n",
    "# optimizer = torch.optim.NAdam(params, lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, momentum_decay=0.004)\n",
    "# optimizer = torch.optim.RAdam(params, lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0\n",
    "# optimizer = torch.optim.Rprop(params, lr=lr, etas=(0.5, 1.2), step_sizes=(1e-06, 50))\n",
    "\n",
    "\n",
    "#lr_scheduler = None\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=3,gamma=0.1)\n",
    "#lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=12, gamma=0.1)\n",
    "                                               \n",
    "\n",
    "# initialize the Averager\n",
    "loss_hist = Averager()\n",
    "iou_thresholds = [x for x in np.arange(0.5, 0.76, 0.05)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace90be0",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f491863",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "precision = []\n",
    "for epoch in range(num_epochs):\n",
    "    itr = 1\n",
    "    train_loss_hist, end, start = train(train_data_loader, lr_scheduler,\n",
    "                                        model, optimizer, device,\n",
    "                                        epoch, loss_hist, itr)\n",
    "    valid_prec = validate(valid_data_loader, model, device, iou_thresholds)\n",
    "    print(f\"Took {(end-start)/60:.3f} minutes for epoch# {epoch} to train\")\n",
    "    print(f\"Epoch #{epoch} Train loss: {train_loss_hist.value}\")  \n",
    "    print(f\"Epoch #{epoch} Validation Precision: {valid_prec}\")  \n",
    "    train_loss.append(train_loss_hist.value)\n",
    "    precision.append(valid_prec)\n",
    "    \n",
    "    # update the learning rate\n",
    "    if lr_scheduler is not None:\n",
    "        lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3cd689",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b3a4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'fasterrcnn_resnet50_fpn_pneumonia_detection.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ae7766",
   "metadata": {},
   "source": [
    "# plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b4a132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss\n",
    "plt.figure()\n",
    "plt.plot(train_loss, label='Training loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot the validation precision\n",
    "plt.figure()\n",
    "plt.plot(precision, label='Validation precision')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98a2d82",
   "metadata": {},
   "source": [
    "# Tensoboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73478bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29f4e860",
   "metadata": {},
   "source": [
    "# Test model and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28867eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "images_test_path = 'D:/Datasets/LDA/RSNA/stage_2_test_images'\n",
    "\n",
    "test_images = os.listdir(images_test_path)\n",
    "print(f\"Validation instances: {len(test_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5343b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a model; pre-trained on COCO\n",
    "model = get_model()\n",
    "\n",
    "# os.makedirs('../validation_predictions', exist_ok=True)\n",
    "model.load_state_dict(torch.load('./fasterrcnn_resnet50_fpn_pneumonia_detection.pth'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b27ca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prediction_string(boxes, scores):\n",
    "    pred_strings = []\n",
    "    for j in zip(scores, boxes):\n",
    "        pred_strings.append(\"{0:.4f} {1} {2} {3} {4}\".format(j[0], \n",
    "                                                             int(j[1][0]), int(j[1][1]), \n",
    "                                                             int(j[1][2]), int(j[1][3])))\n",
    "\n",
    "    return \" \".join(pred_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01e4c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_threshold = 0.8\n",
    "img_num = 0\n",
    "results = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, image in tqdm(enumerate(test_images), total=len(test_images)):\n",
    "\n",
    "        orig_image = cv2.imread(f\"{images_test_path}/{test_images[i]}\", cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float)\n",
    "        image = torch.tensor(image, dtype=torch.float).cuda()\n",
    "        image = torch.unsqueeze(image, 0)\n",
    "\n",
    "        model.eval()\n",
    "        cpu_device = torch.device(\"cpu\")\n",
    "\n",
    "        outputs = model(image)\n",
    "        \n",
    "        outputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\n",
    "        if len(outputs[0]['boxes']) != 0:\n",
    "            for counter in range(len(outputs[0]['boxes'])):\n",
    "                boxes = outputs[0]['boxes'].data.cpu().numpy()\n",
    "                scores = outputs[0]['scores'].data.cpu().numpy()\n",
    "                boxes = boxes[scores >= detection_threshold].astype(np.int32)\n",
    "                draw_boxes = boxes.copy()\n",
    "                boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n",
    "                boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n",
    "                \n",
    "            for box in draw_boxes:\n",
    "                cv2.rectangle(orig_image,\n",
    "                            (int(box[0]), int(box[1])),\n",
    "                            (int(box[2]), int(box[3])),\n",
    "                            (0, 0, 255), 3)\n",
    "        \n",
    "            plt.imshow(cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB))\n",
    "            plt.axis('off')\n",
    "            plt.savefig(f\"{test_images[i]}\")\n",
    "            plt.close()\n",
    "                \n",
    "            result = {\n",
    "                'patientId': test_images[i].split('.')[0],\n",
    "                'PredictionString': format_prediction_string(boxes, scores)\n",
    "            }\n",
    "            results.append(result)\n",
    "        else:\n",
    "            result = {\n",
    "                'patientId': test_images[i].split('.')[0],\n",
    "                'PredictionString': None\n",
    "            }\n",
    "            results.append(result)\n",
    "\n",
    "sub_df = pd.DataFrame(results, columns=['patientId', 'PredictionString'])\n",
    "print(sub_df.head())\n",
    "sub_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b1d3ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
